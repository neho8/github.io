<html lang="en" class="u-responsive-lg"><head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta charset="utf-8">
  <meta name="keywords" content="Post 1 Headline">
  <meta name="description" content="">
  <title>Earth Observation Essentials</title>
  <link rel="stylesheet" href="../nicepage.css" media="screen">
  <link rel="stylesheet" href="Blog-Template.css" media="screen">
  <link rel="stylesheet" href="../Post-Template.css" media="screen">
  <link rel="shortcut icon" href="../images/favicon2.png" type="image/x-icon">

  <link rel="stylesheet" href="../about.css">
  <script class="u-script" type="text/javascript" src="../jquery.js" defer=""></script>
  <script class="u-script" type="text/javascript" src="../nicepage.js" defer=""></script>
  <meta name="generator" content="Nicepage 5.13.1, nicepage.com">
  <link id="u-theme-google-font" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,500,500i,700,700i,900,900i|Open+Sans:300,300i,400,400i,500,500i,600,600i,700,700i,800,800i">

  <script type="application/ld+json">{
		"@context": "http://schema.org",
		"@type": "Organization",
		"name": ""
}</script>
</head>
<body class="u-body u-palette-1-base u-xl-mode" data-lang="en">
  <header class="u-box-shadow u-clearfix u-header u-white u-header" id="sec-6e12">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h3 class="u-text u-text-custom-color-1 u-text-default u-text-1">
          <a class="u-active-none u-border-none u-btn u-button-link u-button-style u-hover-none u-none u-text-palette-1-base u-btn-1" href="../index.html">Nehoray</a>
        </h3>
        <nav class="u-menu u-menu-one-level u-offcanvas u-menu-1">
          <div class="menu-collapse" style="font-size: 1rem; letter-spacing: 0px; text-transform: uppercase; font-weight: 700;">
            <a class="u-button-style u-custom-active-border-color u-custom-active-color u-custom-border u-custom-border-color u-custom-borders u-custom-hover-border-color u-custom-hover-color u-custom-left-right-menu-spacing u-custom-padding-bottom u-custom-text-active-color u-custom-text-color u-custom-text-decoration u-custom-text-hover-color u-custom-top-bottom-menu-spacing u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="#">
              <svg class="u-svg-link" viewBox="0 0 24 24">
                <use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#menu-hamburger"></use>
              </svg>
              <svg class="u-svg-content" version="1.1" id="menu-hamburger" viewBox="0 0 16 16" x="0px" y="0px" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg">
                <g>
                  <rect y="1" width="16" height="2"></rect>
                  <rect y="7" width="16" height="2"></rect>
                  <rect y="13" width="16" height="2"></rect>
                </g>
              </svg>
            </a>
          </div>
          <div class="u-custom-menu u-nav-container">
            <ul class="u-nav u-spacing-30 u-unstyled u-nav-1">
              <li class="u-nav-item">
                <a class="u-border-5 u-border-active-palette-1-base u-border-hover-palette-1-light-1 u-border-no-left u-border-no-right u-border-no-top u-button-style u-nav-link u-text-active-grey-90 u-text-grey-90 u-text-hover-grey-90" href="../index.html" style="padding: 10px 12px;">Home</a>
              </li>
              <li class="u-nav-item">
                <a class="u-border-5 u-border-active-palette-1-base u-border-hover-palette-1-light-1 u-border-no-left u-border-no-right u-border-no-top u-button-style u-nav-link u-text-active-grey-90 u-text-grey-90 u-text-hover-grey-90" href="../GIS/Course.html" rel="nofollow" style="padding: 10px 12px;">GIS Foundations</a>
              </li>
              <li class="u-nav-item">
                <a class="u-border-5 u-border-active-palette-1-base u-border-hover-palette-1-light-1 u-border-no-left u-border-no-right u-border-no-top u-button-style u-nav-link u-text-active-grey-90 u-text-grey-90 u-text-hover-grey-90" href="newcomers-earth-observation-guide.html" rel="nofollow" style="padding: 10px 12px;">Earth Observation</a>
              </li>
            </ul>
          </div>
          <div class="u-custom-menu u-nav-container-collapse">
            <div class="u-black u-container-style u-inner-container-layout u-opacity u-opacity-95 u-sidenav">
              <div class="u-inner-container-layout u-sidenav-overflow">
                <div class="u-menu-close"></div>
                <ul class="u-nav u-popupmenu-items u-unstyled u-nav-2" style="margin-left: 20px;">
                  <li class="u-nav-item">
                    <a class="u-button-style u-nav-link" href="../index.html">Home</a>
                  </li>
                  <li class="u-nav-item">
                    <a class="u-button-style u-nav-link active" href="../GIS/Course.html">GIS Foundations</a>
                  </li>
                  <li class="u-nav-item">
                    <a class="u-button-style u-nav-link active" href="newcomers-earth-observation-guide.html">Earth Observation</a>
                  </li>
                </ul>
              </div>
            </div>
          </div> 
            <div class="u-black u-menu-overlay u-opacity u-opacity-70"></div>
          <style class="offcanvas-style">            .u-offcanvas .u-sidenav { flex-basis: 250px !important; }            .u-offcanvas:not(.u-menu-open-right) .u-sidenav { margin-left: -250px; }            .u-offcanvas.u-menu-open-right .u-sidenav { margin-right: -250px; }            @keyframes menu-shift-left    { from { left: 0;        } to { left: 250px;  } }            @keyframes menu-unshift-left  { from { left: 250px;  } to { left: 0;        } }            @keyframes menu-shift-right   { from { right: 0;       } to { right: 250px; } }            @keyframes menu-unshift-right { from { right: 250px; } to { right: 0;       } }            </style></nav></div>
        
      
    </header>
  <section class="u-clearfix u-palette-6-light-4 u-section-1" id="sec-4076">
    <div class="u-clearfix u-sheet u-sheet-1">     
  <h2 class="u-text u-text-custom-color-1 u-text-default u-text-1" style="margin-bottom: 20px;margin-top: 60px; ">Earth Observation Essentials</h2>  <p><span style="font-size: 1.5rem;" id="toc-title1"><b>Table of Contents</b></span></p>
    <ul style="list-style-type: none;"><li><strong><a href="#ref_1">1. Introduction</a></strong></li>
    <li><strong><a href="#ref_2">2. Types of Earth Observation Imagery</a></strong></li>
    <ul style="list-style-type: none;"><li><a href="#ref_2.1">2.1 Passive imagery</a></li>
    <ul style="list-style-type: none;"><li><a href="#ref_2.1.1">2.1.1 Panchromatic</a></li>
    <li><a href="#ref_2.1.2">2.1.2 Multi-spectral</a></li>
    <li><a href="#ref_2.1.3">2.1.3 Pan-sharpened</a></li>
    <li><a href="#ref_2.1.4">2.1.4 Hyper-spectral</a></li>
    <li><a href="#ref_2.1.5">2.1.5 Microwave Radiometry</a></li>
    </ul><li><a href="#ref_2.2">2.2 Active imagery</a></li>
    <ul style="list-style-type: none;"><li><a href="#ref_2.2.1">2.2.1 Synthetic Aperture Radar</a></li>
    <li><a href="#ref_2.2.2">2.2.2 Lidar</a></li>
    <li><a href="#ref_2.2.3">2.2.3 Radar Altimetry</a></li>
    <li><a href="#ref_2.2.4">2.2.4 GNSS-R</a></li>
    <li><a href="#ref_2.2.5">2.2.5 Radar Scatterometry</a></li>
    </ul><li><a href="#ref_2.3">2.3 Atmospheric Chemistry</a></li>
    <li><a href="#ref_2.4">2.4 Gravity field measurements</a></li>
    <li><a href="#ref_2.5">2.5 3D Models</a></li>
    <li><a href="#ref_2.6">2.6 Data Processing<br></a></li>
    </ul><li><strong><a href="#ref_3">3.Parameters Related to EO Imagery</a></strong></li>
    <ul style="list-style-type: none;"><li><a href="#ref_3.1">3.1 Spatial Resolution</a></li>
    <li><a href="#ref_3.2">3.2 Scene size</a></li>
    <li><a href="#ref_3.3">3.3 Revisit time</a></li>
    <li><a href="#ref_3.4">3.4 Other image quality-related parameters</a></li>
    <li><a href="#ref_3.5">3.5 Accessibility of EO Products</a></li>
    </ul><li><strong><a href="#ref_4">4.List of Remote Sensing Satellite Systems</a></strong></li>
    <li><strong><a href="#ref_5">5.Pricing Policy</a></strong></li>
    <li><strong><a href="#ref_6">6.How to Access Data</a></strong></li>
    <li><strong><a href="#ref_7">7.Future Trends</a></strong></li>
    <li><strong><a href="#ref_8">8.Reference Sources</a></strong></li>
    <li><strong><a href="#ref_9">9.Useful Links</a></strong></li>
    <li><strong><a href="#eo_acro">10.Acronyms</a></strong></li>
    <p class="m-d-n"></p>
    </ul>
    &nbsp;
    <h3 id="1"><a name="ref_1" id="ref_1"></a>1. Introduction</h3>
    <p>The aim of this guide is to help non-experts in providing a starting point in the decision process for selecting an appropriate Earth Observation (EO) solution. EO is defined as the process of acquiring observations of the Earth’s surface and atmosphere via remote sensing instruments. The acquired data is usually in the form of digital imagery. Earth’s surface can be observed from different platforms, each presenting its own advantages and limitations. Aerial platforms, for instance, generally provide the best resolutions and are very adjustable to the users’ needs, but the high cost of chartering a plane and paying the related manpower (pilots and technicians) restricts its use. Drones, also called Remotely Piloted Aircraft Systems (RPAS), are a fast-growing technology that tackles this cost problem, but regulations and their low carrying capacity currently limits their range of activity. On the other hand, satellites allow for reliable, true global coverage even above the most remote locations enabling regular repeat observations.</p>
    <p>This document focuses primarily on operational applications of Earth Observation data.&nbsp; Many other science applications are also possible.</p>
    &nbsp;
    <h3 id="2"><a name="ref_2" id="ref_2"></a>2. Types of Earth Observation Imagery</h3>
    <p>In this section, a classification of the different kinds of available Earth Observation imagery is proposed. The main distinctions are made on the nature (passive or active) of the sensing instrument providing the image and on the wavelength of the electromagnetic spectrum in which the observation is made. The electromagnetic transparency of the atmosphere, as illustrated in Figure 1, allows for the observation of Earth’s surface in the visible spectrum (0.39 to 0.70 μm), in a part of the infrared spectrum (from 0.70 to 14 μm) and in the radio wave range (from 1 cm to 11m).</p>
    &nbsp;
    <h4 id="2.1"><a name="ref_2.1" id="ref_2.1"></a>2.1 Passive imagery</h4>
    <p>In passive imagery systems, sensors are designed to detect electromagnetic emissions from constituents of the Earth's surface and atmosphere. These emissions can be locally produced (e.g. thermal radiation from vegetation in the infrared spectrum) or be the result of reflected sunlight in the visible spectrum. Hence, passive imagery is usually dependant on the day-night cycle and can be degraded or blocked by perturbations coming from unwanted sources of emissions or cloud cover.</p>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01">
      <img src="images//figure1-782x426.png" title="Atmospheric electromagnetic transparency" width="782" height="426">
      <p><strong>Figure 1</strong>: Atmospheric electromagnetic transparency (Source: <a href="http://commons.wikimedia.org/wiki/File:Atmospheric_electromagnetic_opacity.svg" target="_blank">http://commons.wikimedia.org/wiki/File:Atmospheric_electromagnetic_opacity.svg</a>) </p></div>
    &nbsp;
    <h4 id="2.1.1"><a name="ref_2.1.1" id="ref_2.1.1"></a>2.1.1 Panchromatic</h4>
    <p>Panchromatic images are the result of the measure of light intensity over a broad range of the electromagnetic spectrum. Collecting light from a wide range of wavelengths allows for more energy being collected and hence high resolution images (up to 30 cm in resolution for the best commercially available satellite instruments).</p>
    <p>A standard example of panchromatic measurement will measure the light intensity coming from the observed scene in the full visible spectrum. This measurement would typically cover wavelengths between 0.47 and 0.83 μm. The resulting product is generally an image displayed as shades of grey, such as presented in Figure 2.</p>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01">
      <img src="images/figure2-727x535.png" title="Example of panchromatic image" width="727" height="535">
      <p><strong>Figure 2</strong></p>
    </div>
    <p>Another example of panchromatic measurement is done by thermal infrared sensors, at wavelengths between 10 and 12 μm. The intensity of the IR radiation reaching the satellite is directly correlated with the temperature of the object emitting that radiation. Regions where the ground or the ocean is warm will emit the most intense radiation.</p>
    <p>Because IR is constantly emitted by the Earth and by clouds, it is possible to obtain IR satellite imagery even when the scene is not illuminated by the sun. In contrast, visible satellite imagery which relies on sunlight reflected up to the satellite can only be obtained during the daylight hours.</p>
    &nbsp;
    <p><strong><a name="ref_2.1.2" id="ref_2.1.2"></a>2.1.2 Multi-spectral</strong><br><br> Multi-spectral imagery denotes the remote sensing of an observed scene in several narrow bands of the electromagnetic spectrum. Since the range of wavelengths contributing to the radiation energy detected by the sensor is reduced, multi-spectral instruments will typically have to collect energy on larger spatial extents to “fill” the imaging detector, resulting in a lower resolution than for panchromatic images.</p>
    <p>A common example of multi-spectral images is the production of “natural colour” images by the combination of measurements in 3 bands of the visible spectrum (narrow bands centred around the blue, green and red wavelengths), in the same way as is done in classical consumer cameras. See Figure 3 (left-hand side) for an example of a "natural colour" image.</p>
    <p>Multi-spectral images are not restricted to the visible spectrum: measurements can be done in the infrared (IR) fields, ultraviolet (UV), microwave, etc. Figure 3 (right-hand side) presents an example of a "false colour" image, combining the green band (displayed in the blue component of the image), the red band (displayed in the green component of the image) and a near infrared band (displayed in the red component of the image). This visualisation combination allows highlighting the presence and health of the vegetation: healthy vegetation creates chlorophyll which reflects near-infrared energy, and therefore appears in darker red on the image.</p>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01">
      <img src="images/figure3-798x278.png" title="Example of multi-spectral images" width="798" height="278">
      <p><strong>Figure 3:</strong> 3-band multi-spectral imagery</p>
    </div>
    <p>Many other combinations of wavelength bands are possible, depending on the information to be extracted. For example:</p>
    <ul>
      <li>Shortwave infrared (red), near infrared (green), and green (blue): <br> often used to show floods or newly burned land</li><br>
      <li>Blue (red), two different shortwave infrared bands (green and blue): <br> used to differentiate between snow, ice, and clouds</li><br>
      <li>Blue (blue), near infrared (green), mid infrared (red): <br> used to picture on one image water depth, vegetation coverage, soil moisture content, and the presence of fires</li>
    </ul>  
    &nbsp;
    <p id="2.1.3"><a name="ref_2.1.3" id="ref_2.1.3"></a><strong>2.1.3 Pan-sharpened</strong></p>
    <p>Pan-sharpening is a numerical process that merges multi-spectral images with panchromatic images to provide high resolution coloured images. This technique is useful to perform image analysis combining the spectral resolution of multi-spectral images with the improved spatial resolution of panchromatic images. This is illustrated in Figure 4.</p>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01">
      <img src="images/figure4-773x212.png" title="Illustration of pan-sharpening process" width="773" height="212">
      <p><strong>Figure 4:</strong> Example of Pan-Sharpening</p>
    </div>
    &nbsp;
    <p id="2.1.4"><a name="ref_2.1.4" id="ref_2.1.4"></a><strong>2.1.4 Hyper-spectral</strong></p>
    <table class="xs-w-full" style="width: 390px;" border="0" cellpadding="5" align="left"><tbody><tr><td>
    <p><img src="images/figure5.jpg" title="Example of hyper-spectral data product" width="380" height="230" style="float: left;"></p>
    </td>
    </tr><tr><td><strong>Figure 5</strong>: Example of Hyperspectral Data Product</td>
    </tr></tbody></table><p>
      Hyperspectral imagery aims at obtaining a nearly-continuous spectrum for each pixel in the image of a scene, extending the benefits of multi-spectral imagery, which measures light intensity on a limited number of separate bands of the electromagnetic spectrum. Figure 5 provides an example of representation of a hyperspectral data product, each layer of the cube picturing the same 2D scene observed in one specific wavelength λ, allowing for more detailed and accurate analysis of the observed features.</p>
    <p>For each pixel, a hyperspectral sensor acquires the light intensity for a large number (typically a few tens to several hundred) of contiguous narrow spectral bands. To every pixel in the image is thus attached a nearly continuous spectrum. The high spectral resolution of a hyperspectral imager allows for detection, identification and quantification of surface materials, as well as inferring biological and chemical processes.</p>
    <p>Hyperspectral Earth Observation is for now mainly limited to aerial imagery and scientific demonstration missions.</p>
    <p>In addition, MWR measurement data are useful for the determination of surface emissivity and soil moisture over land, for surface energy budget investigations to support atmospheric studies, and for ice characterisation.</p>
    &nbsp;
    <p id="2.1.4"><a name="ref_2.1.5" id="ref_2.1.5"></a><strong>2.1.5 Microwave Radiometry</strong></p>
    <p>The main objective of the Microwave Radiometer (MWR) is the measurement of the integrated atmospheric water vapour column and cloud liquid water content, as correction terms for the radar altimeter signal (see Section <a href="#ref_2.2.3">2.2.3 Radar Altimetry</a>).</p>
    &nbsp;
    <p id="2.2" style="margin-bottom: 20px;"><a name="ref_2.2" id="ref_2.2"></a><strong>2.2 Active imagery</strong></p>
    <p style="margin-top: 20px;">In active imagery systems, instruments are composed of a transmitter that sends out a specific electromagnetic signal and of a sensor receiving the interaction of the signal with the Earth’s surface. Such observations are not dependent on solar illumination.</p>
    &nbsp;
    <p id="2.2.1" style="margin-bottom: 20px;"><a name="ref_2.2.1" id="ref_2.2.1"></a><strong>2.2.1 Synthetic Aperture Radar</strong></p>
    <p style="margin-top: 20px;">The most common active sensor used for Earth Observation is the Synthetic Aperture Radar (SAR). This instrument transmits electromagnetic pulses towards the Earth’s surface where they are reflected or scattered by the surface features. The instrument’s antenna can detect and record the return pulses. The intensity of the return pulse and the time it takes to arrive back at the antenna are used to generate SAR imagery.</p>
    <p>The main advantage of radar imaging is that it is insensitive to the day/night cycle and most of the time to the meteorological conditions (shorter wavelength signals such as X-band can be degraded by heavy intense rain cells). The selected radio band impacts what is observed from the scene by influencing the level at which the incident radiation will backscatter.&nbsp;</p>
    <p>Applications include (for instance) ship detection, oil spill detection, sea ice monitoring (see Figure 6), forest monitoring, soil moisture, critical infrastructure, etc.</p>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01">
      <img src="images/figure6-780x505.jpg" title="Example of SAR images monitoring the formation of new icebergs" width="780" height="505">
    <p><strong>Figure 6:</strong> Example of SAR imagery for monitoring formation of Icebergs (Source: ESA ENVISAT)</p>
    </div>
    <p>By using a technique known as SAR&nbsp; interferometry,&nbsp; highly accurate measurements&nbsp; of&nbsp; geophysical&nbsp; parameters&nbsp; such&nbsp; as&nbsp; surface&nbsp; topography,&nbsp; ground&nbsp; deformation&nbsp; and&nbsp; subsidence and glacier movements can be made. In SAR interferometry, the&nbsp; phase&nbsp; of&nbsp; two&nbsp; or&nbsp; more&nbsp; complex&nbsp; radar&nbsp; images are compared that have&nbsp; been acquired from slightly different positions or at different times. Since the phase of each SAR image pixel contains range information that is accurate to a small fraction of the radar wavelength, it is possible to detect and measure path length differences with centimetric or even millimetric precision.&nbsp;</p>
    <p>With&nbsp; across-track&nbsp; interferometry the&nbsp; radar&nbsp; images&nbsp; are&nbsp; acquired&nbsp; from&nbsp; mutually&nbsp; displaced&nbsp; flight&nbsp; tracks , enabling (for instance)&nbsp; a&nbsp; precise&nbsp; measurement&nbsp; of&nbsp; the&nbsp; surface&nbsp; topography. By&nbsp; using&nbsp; an&nbsp; external&nbsp; DEM,&nbsp; the&nbsp; topographic&nbsp; information can be subtracted from the interferogram, leading to a differential SAR interferometric&nbsp; measurement&nbsp; where subtle (mm) changes&nbsp; of&nbsp; the&nbsp; range&nbsp; distance&nbsp; between&nbsp; the&nbsp; two acquisitions (e.g. due to subsidence) can be detected. Further potential is possible by comparison of the coherence between several data acquisitions, which can be used for land classification and change detection.</p>
    <p>With&nbsp; along-track&nbsp; interferometry, the&nbsp; radar&nbsp; images&nbsp; are&nbsp; acquired&nbsp; from&nbsp; one&nbsp; and&nbsp; the&nbsp; same&nbsp; flight&nbsp; track&nbsp; but&nbsp; at&nbsp; different&nbsp; times, enabling (for instance) the observation of ocean surface currents.</p>
    &nbsp;
    <p id="2.2.2"><a name="ref_2.2.2" id="ref_2.2.2"></a><strong>2.2.2 Lidar</strong></p>
    <p>Lidar (Light Detection And Ranging) EO uses the same principle as SAR but works in the IR, visible or UV wavelengths. Lidars are used for precise measurement of topographic features, monitoring growth or decline of glaciers, profiling clouds, measuring winds, studying aerosols and quantifying various atmospheric components.</p>
    <p>The Atmospheric Lidar ATLID on ESA’s EarthCare mission will provide vertical profiles of aerosols and thin clouds. It operates at a wavelength of 355nm and has a high-spectral resolution receiver and depolarisation channel.</p>
    <p>The Atmospheric Laser Doppler Lidar Instrument ALADIN on ESA’s Aeolus-ADM mission will measure Line-of-Sight wind profiles at different levels in the atmosphere from the troposphere to the lower stratosphere with vertical resolution of 250 m - 2 km. It operates at a wavelength of 355nm, with spectrometers for molecular Rayleigh and aerosol/cloud Mie backscatter.&nbsp; ALADIN will be the first wind lidar in space to obtain aerosol/cloud optical properties (backscatter and extinction coefficients).</p>
    &nbsp;
    <p><a name="ref_2.2.3" id="ref_2.2.3"></a><strong>2.2.3 Radar Altimetry</strong></p>
    <table class="xs-w-full" style="width: 410px;" border="0" cellpadding="5" align="left"><tbody><tr><td>
    <p><img src="images/Altimetry-derived%20mean%20dynamic%20topography.png" title="Altimetry-derived mean dynamic topography" width="400" height="400" style="float: left; margin-right: 20px;"></p>
    </td>
    </tr><tr><td>&nbsp;</td>
    </tr></tbody></table><p>Radar altimeters are active sensors that use the ranging capability of radar to measure the surface topography profile along the satellite track. They provide precise measurements of a satellite's height above the ocean by measuring the time interval between the transmission and reception of very short electromagnetic pulses.</p>
    <p>Radar altimeter measurements can infer various parameters, including time-varying sea-surface height (ocean topography), the lateral extent of sea ice, the altitude of large icebergs above sea level, the topography of land and ice sheets, and even the sea floor, while satellite altimetry also provides data for mapping sea-surface wind speeds and significant wave heights.</p>
    <p>Jason-3 and Jason-CS (Sentinel 6) are contributing radar altimetry missions of the Copernicus programme, which will provide the continuity of critical high precision observations of ocean surface topography until 2030+, in full synergy with the marine mission of the Copernicus Sentinel 3.<strong><br></strong></p>    
    <p class="figure large medium-height editable block"><strong>Figure 7: </strong>Altimetry-derived mean dynamic topography</p>
    &nbsp;
    <p><a name="ref_2.2.4" id="ref_2.2.4"></a><strong>2.2.4 GNSS-R</strong></p>
    <table class="xs-w-full" style="width: 530px;" border="0" cellpadding="5" align="left"><tbody><tr><td>
    <p><img src="images/Starlab%20GNSS-R%20Sensor%20Oceanpal.png" title="Starlab GNSS-R Sensor Oceanpal" width="520" height="389" style="float: left; margin-right: 20px;"></p>
    </td>
    </tr></tbody></table><p>GNSS reflectometry (GNSS-R) is a relatively new category of satellite navigation applications which entails a method of remote sensing to receive and process microwave signals reflected from various surfaces to extract information about those surfaces.</p>
    <p>In this process, the GNSS satellite acts as the transmitter and an airplane or Low Earth Orbit (LEO) satellite as the receiving platform. For altimetry applications, a GNSS-R receiver can also be placed on the land.</p>
    <p>An advantage of GNSS-R remote sensing is the ubiquity of signal sources, including GPS, Galileo, GLONASS, and Beidou/Compass.</p>
    <p>A wide range of applications is possible such as wide-swath altimetry, sea-wind retrieval, and measurement of seawater salinity and ice-layer density, as well as humidity measurements over land.</p>
    <p class="figure large medium-height editable block"><strong>Figure 8: </strong>Starlab GNSS-R Sensor Oceanpal for monitoring lake level in ESA Applications project.</p>
    &nbsp;
    <p><a name="ref_2.2.5" id="ref_2.2.5"></a><strong>2.2.5 Radar Scatterometry</strong></p>
    <table class="xs-w-full" style="width: 306px;" border="0" cellpadding="5" align="left"><tbody><tr><td>
    <img src="images/Composite%20radar%20scatterometer.png" title="Composite radar scatterometer image of Antarctica" width="291" height="290" style="float: left; margin-right: 20px;">    </td>
    </tr></tbody></table><p>A radar scatterometer is a microwave radar sensor used to measure the reflection or scattering effect produced while scanning the surface of the Earth from an aircraft or a satellite. It provides a measure of wind speed and direction near the sea surface.</p>
    <p>The radar scatterometer measures the backscatter from small (cm) waves at the sea surface, at skew incidence angles. From these sea roughness measurements the wind vector at 10 m height is calculated. Radar scatterometer data are important sources of information for Numerical Weather Prediction and oceanography.</p>
    <p>Radar scatterometers can also provide information such as sea ice cover.&nbsp; Sea ice typically reflects more of the radar energy emitted by the sensor than the surrounding ocean, so it appears brighter in a radar scatterometer image.</p>
    <p class="figure large medium-height editable block"><strong>Figure 9: </strong>Composite radar scatterometer image of Antarctica, 19 July 2003, from the QuikSCAT satellite (Source: David Long, Brigham Young University Center for Remote Sensing, <a href="https://nsidc.org/cryosphere/seaice/study/active_remote_sensing.html" target="_blank">https://nsidc.org/cryosphere/seaice/study/active_remote_sensing.html</a>)</p>
    &nbsp;
    <h4><a name="ref_2.3" id="ref_2.3"></a>2.3 Atmospheric Chemistry</h4>
    <p>Atmospheric Chemistry can be monitored using a range of EO instruments using various techniques and different parts of the electromagnetic spectrum. Each atmospheric gas is characterised by its “absorption” and “emission” spectra, which describe how the molecules respond to different frequencies of radiation. EO remote sensing instruments exploit these “signatures” to provide information on atmospheric composition, using measurements over a range of wavelengths between UV and microwave.</p>
    <p>Atmospheric absorption tends to be dominated by water vapour, carbon dioxide and ozone, with smaller contributions from methane and other trace gases. Relatively broadband instruments can be used for measurements of the dominant gases, but high spectral resolution sensors are needed to make measurements of other species since they produce weaker signals and these must be discriminated from the signals of more abundant gases.</p>
    <p>Atmospheric Chemistry instruments are typically operated in either nadir-viewing mode looking vertically directly down to measure the radiation emitted or scattered, or in a limb-viewing mode that scans positions beyond the horizon to observe paths through the atmosphere at different altitudes.&nbsp; Nadir-viewing instruments provide high spatial resolution in the horizontal direction but limited vertical resolution, whereas limb-viewing instruments provide a high vertical resolution (a few km) but limited horizontal resolution (tens of km at best).</p>
    <p>Atmospheric Chemistry sensors may be either Active or Passive. Some examples of Active atmospheric chemistry sensors are atmospheric lidars (c.f. <a href="#ref_2.2.2">2.2.2 Lidar</a>), whereas examples of Passive atmospheric chemistry sensors are imaging spectrometers, multispectral radiometers, solar occultation sensors and microwave limb sounders.</p>
    &nbsp;
    <h4><a name="ref_2.4" id="ref_2.4"></a>2.4 Gravity field measurements</h4>
    <p>Gravity field measurements from space rely on one of three types of techniques:</p>
    <ul>
      <li>Use of single or multiple accelerometers on one or more satellites to derive gravity or gravity gradient information.</li><br>
      <li>Precise satellite orbit determination (using satellite to ground navigation systems and satellite laser ranging systems), and separation of satellite motion induced by the Earth’s gravitational force from other forces such as solar radiation and aerodynamic drag.</li><br>
      <li>Satellite-to-satellite tracking (e.g. by GPS or microwave link) to measure the relative speed variations of two satellites induced by gravitational forces.</li>
    </ul>  
    <p>Gravity field measurements from space provide significant advances for improved measurement of the “geoid” and its time variations. The geoid (the surface of equal gravitational potential at mean sea level) reflects the irregularities in the Earth’s gravity field at the surface due to the inhomogeneous mass and density distribution in the Earth’s interior.</p>
    <p>More accurate models of the mean geoid and its temporal variability are important for applications such as for making measurements of absolute ocean currents, their transport of heat and other properties, for providing estimates of the thickness of polar ice sheets and their variations, and for making estimates of the mass/volume redistribution of freshwater in order to further understand the hydrological cycle.</p>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01">
    <img src="images/First%20Global%20Gravity%20Model.jpg" title="First Global Gravity Model from ESA’s GOCE mission " width="700" height="462">
    <p><strong>Figure 10: </strong>First Global Gravity Model from ESA’s GOCE mission (Source: <a href="http://www.esa.int/spaceinimages/Images/2010/06/GOCE_first_global_gravity_model" target="_blank">http://www.esa.int/spaceinimages/Images/2010/06/GOCE_first_global_gravity_model</a>)</p>
    </div>
    &nbsp;
    <h4 id="2.3"><a name="ref_2.5" id="ref_2.5"></a>2.5 3D Models</h4>
    <p>EO data can also be processed in order to produce 3D models of the Earth’s surface. 3D models are used for many applications, such as military operations, flight simulator development, disaster management, mapping of buildings, updating and keeping cadastral databases current, change detection and virtual reality (see for instance <a href="http://www.satimagingcorp.com/applications/engineering-and-construction/3d-city-and-urban-modeling/" target="_blank">http://www.satimagingcorp.com/applications/engineering-and-construction/3d-city-and-urban-modeling/</a>).</p>
    <p>Several types of processes are available. Images of a scene taken from different points of view can be combined in order to reconstruct depth information. Figure 11 illustrates this stereoscopic technique with 2 (Stereo) or 3 (Tri-Stereo) images taken from different angles. SAR and Lidar instruments also provide altitude information that can be used to help build 3D surface models.</p>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01">
      <img src="images/figure7-762x223.png" title="Illustration of stereoscopic techniques" width="762" height="290">
    <p><strong>Figure 11:</strong> Illustration of Stereoscopic techniques</p>
    </div>
    <p>As stated in Section <a href="#ref_2.2.1">2.2.1 Synthetic Aperture Radar,</a> the technique of across-track SAR interferometry can also be used to generate 3D surface models.</p>
    <table class="xs-w-full" style="width: 410px;" border="0" cellpadding="5" align="left"><tbody><tr><td>
    <p><img src="images/figure9.jpg" title="Distinction between DSM and DTM" width="400" height="180" style="float: left;"></p>
    </td>
    </tr><tr><td><strong>Figure 12:</strong> Distinction between DSM and DTM (Source: <a href="http://www.geoimage.com.au/" target="_blank">geoimage.com.au</a>)</td>
    </tr></tbody></table><p>A distinction is made between Digital Surface Models (DSMs), which represent the Earth's surface with all objects on it, and Digital Terrain Models (DTMs), which represent the bare ground surface without any objects like plants and buildings (see Figure 12). Another terminology, Digital Elevation Model (DEM), is also frequently encountered and can refer to either DSM, DTM or both of them, no convention being commonly accepted.</p>
    &nbsp;
    <h4 id="2.4"><a name="ref_2.6" id="ref_2.6"></a>2.6 Data Processing</h4>
    <p>When acquired by satellite sensors and downloaded to ground stations, data are in a raw format. EO products can then be bought by the customer, with or without a wide range of different types of pre-processing. Some applications might require raw and unaltered data coming from the instrument, while most use cases will benefit from different treatments improving the interpretability of the EO data. Image providers usually define several levels of treatment combining different processes, and charged at different prices, for example:</p>
    <ul>
      <li>Various radiometric corrections: sensor irregularities correction, defective pixels identification, etc.</li><br>
      <li>Atmospheric corrections</li><br>
      <li>Scene classification, land/water masks generation</li><br>
      <li>Dynamic range adjustment: adjust contrast and brightness in the image</li><br>
      <li>Ortho-rectification: remove sensor/satellite motion and terrain-related geometric distortions to obtain map-suitable images</li>
    </ul>  
    &nbsp;
    <h3 id="3"><a name="ref_3" id="ref_3"></a>3. Parameters Related to EO Imagery</h3>
    <p>While considering an Earth Observation product, a set of parameters can be defined that will distinguish the capacities provided by different EO satellite systems. The choice must then be done based on the EO User needs. The aim of this section is to provide basic keys to understanding these parameters, in order to facilitate the EO product ordering decision process.</p>
    &nbsp;
    <h4 id="3.1"><a name="ref_3.1" id="ref_3.1"></a>3.1 Spatial Resolution</h4>
    <p>The spatial resolution of an image is one of the key parameters as it relates to the level of detail that can be retrieved from a scene. Image resolution can be measured in several ways; one of the most common, the Ground Sample Distance (GSD), is the distance between adjacent pixel centres measured on the ground. The lower this number is, the finer the detail that can be interpreted from the image.</p>
    <p>It’s commonly considered that low resolution images have a GSD larger than 300 m. Medium resolution is between 300 m and 30 m, high resolution from 30 to 5 m and very high resolution (VHR) below 5 m. Following the performances of the recently launched commercial satellites, a new “very very high" resolution category could be distinguished for resolutions below 1 m. The best commercially available imagery has 30 cm spatial resolution (see Figure 13 for an example).</p>
    <p>Spatial resolution selection is mainly driven by the envisaged application for the EO product. High resolution images will be required for instance to collect data for high precision agriculture, while lower resolutions are enough for applications such as weather forecasting, study of regional vegetation coverage or wide-area weather and cloud patterns.</p>
    <p>Another factor influencing this choice is the size of the scene to observe. High-resolution imagery is more expensive and produces files of large size. High resolution is generally used for areas of interest smaller than 100 square kilometres.</p>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01"><img src="images/figure10-757x426.jpg" title="Example of image with a 30 cm spatial resolution" width="757" height="426">
    <p><strong>Figure 13:</strong> Example of image with 30cm spatial resolution (Source: Digital Globe <a href="http://microsites.digitalglobe.com/30cm/" target="_blank">http://microsites.digitalglobe.com/30cm/</a>)</p>
    </div>
    <p>The National Imagery Interpretability Rating Scale (NIIRS) is used as a standard to quantify the interpretability or usefulness of an image. This "rating" scale, originally inspired by the military to qualify aerial imaging, runs from 0 (worst quality) to 9 (best quality). An excerpt is presented in Figure 14, which also provides an approximate relation between NIIRS scale and GSD (GSD being one of several factors influencing the interpretability of an image).</p>
    <br><br>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01">
        <div class="informaltable block" frame="all">
            <table cellpadding="0" cellspacing="0" style="font-size: medium;">
                <thead>
                    <tr>
                        <th>NIIRS Scale</th>
                        <th>GSD (approx.)</th>
                        <th>Visible</th>
                        <th>Radar</th>
                        <th>Multispectral</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>1</td>
                        <td>&gt; 4.5 m</td>
                        <td>Distinguish between taxi-ways and runways at a large airfield</td>
                        <td>Detect a large cleared swath in a densely wooded area</td>
                        <td>Distinguish between urban and rural areas</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>2.25 - 4.5 m</td>
                        <td>Distinguish between types of houses, boats, etc.</td>
                        <td>Detect large buildings</td>
                        <td>Identify urban road network pattern</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>1.25 - 2.25 m</td>
                        <td>Identify a large surface ship in port by type</td>
                        <td>Detect medium-sized aircraft</td>
                        <td>Identify major street patterns in urban areas</td>
                    </tr>
                    <tr>
                        <td>5</td>
                        <td>0.37 - 0.6 m</td>
                        <td>Identify radar as vehicle-mounted or trailer-mounted</td>
                        <td>Count all medium helicopters</td>
                        <td>Detect ditch irrigation of beet fields</td>
                    </tr>
                    <tr>
                        <td>6</td>
                        <td>0.30 - 0.45 m</td>
                        <td>Identify equipment on a recreational vehicle</td>
                        <td>Distinguish between two adjacent parked cars</td>
                        <td>Detect localized damage to crops</td>
                    </tr>
                    <tr>
                        <td>7</td>
                        <td>0.10 - 0.20 m</td>
                        <td>Identify individual rail ties</td>
                        <td>Detect road/street lamps in an urban residential area</td>
                        <td>Distinguish individual rows of crops</td>
                    </tr>
                    <tr>
                        <td>9</td>
                        <td>&lt; 0.05 m</td>
                        <td>Identify vehicle registration numbers (VRN) on trucks</td>
                        <td>Identify trucks as cab-over-engine or engine-in-front</td>
                        <td>Identify individual tree canopies</td>
                    </tr>
                </tbody>
            </table>
        </div>    
      <p><strong>Figure 14:</strong> Excerpt of NIIRS scale related to GSD (Source: <a href="http://fas.org/irp/imint/niirs.htm" target="_blank">http://fas.org/irp/imint/niirs.htm</a>)</p>
    </div>
    <br class="m-d-n"><br class="m-d-n">
    &nbsp;
    <h4 id="3.2"><a name="ref_3.2" id="ref_3.2"></a>3.2 Scene size</h4>
    <p>The size of the scene to be observed is another important parameter. Earth Observation sensors onboard satellites are characterised by their swath width. The swath of an instrument is the width of the strip on the ground it can image when the satellite orbits around the Earth. The swath depends on the features of the instrument and on the orbit of the satellite. Generally, the higher the spatial resolution, the lower the swath of the instrument. As an example, the very high-resolution (0.46 m) instrument onboard Worldview-2 has a 16.4 km swath, while Sentinel-2 can image strips 290 km wide with a 5 m spatial resolution.</p>
    <p>To cover large areas, VHR imagery requires a large number of images, which has an impact on the data volume to be managed and on the acquisition cost. Therefore, a trade-off analysis between resolution and cost needs to be performed before ordering satellite images.</p>
    <p>Most EO product providers offer online graphical interface tools to select the area of interest, choose the EO products and the satellite system, and request archive images or task new acquisitions. Satellite operators will then generate the operation plan of the satellite based on optimised number of strips, satellite passes, area of interest, etc to satisfy the request and provide a price quotation.</p>
    <p>Operators generally require a minimum area to be ordered (typically 100 square kilometres for VHR imagery).</p>
    &nbsp;
    <h4><strong><a name="ref_3.3" id="ref_3.3"></a>3.3 Revisit time</strong></h4>
    <p>The need for Earth Observation data can be "punctual" (e.g. preparing a road maintenance operation in a remote area), "punctual &amp; urgent" (e.g. assessing flooded areas after a tsunami) or "periodic" (e.g. monitoring crops). The revisit time of a satellite system (i.e. the time elapsed between subsequent observations of the same area of interest) is a decisive factor of choice. This parameter is closely linked to the type of orbit of the satellites.</p>
    <p>Most EO satellites are in specific low Earth polar orbits called "Sun-Synchronous Orbits (SSO)", whose altitude and inclination are precisely calculated so that the satellite will observe, over time, the same scene with the same angle of illumination coming from the Sun. This kind of orbit typically has an altitude of around 700 km and an inclination of 98˚. Due to this high inclination, the revisit time for a satellite will be longer for equatorial areas than for polar regions.</p>
    <p>Two different definitions can be given to the revisit time. From the point of view of the satellite, the revisit time is the elapsed time before the satellite retraces its path, passing over the same exact point on the ground surface. From the point of view of an EO user, the revisit time is defined as the length of time to wait for the satellite system to be able to observe the same point on Earth.</p>
    <p>The difference between these two definitions originates from the "agility" feature of most EO satellites, i.e. the ability of a satellite to modify its attitude in order to observe scenes outside its ground trace (see Figure 15 for different acquisition strategies). To further reduce the revisit time, EO constellations can be used: augmenting the number of satellites in orbit lowers the waiting time between observations of a same scene.</p>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01"><img src="images/figure12-758x187.png" title="Different acquisition strategies using the agility of an EO satellite" width="758" height="230">
    <p><strong>Figure 15:</strong> Different acquisition strategies using the agility of an EO satellite </p>
    </div>
    <p>As an example, the two Pléiades constellation satellites on a SSO are able to acquire images in a +/- 30˚ corridor around their ground trace: while the periodic cycle of their orbits is 26 days, the agility of the satellites combined with the phased orbit of the constellation offer a 2 day revisit for any point on Earth.</p>
    <p>It is worth noting that some EO satellites are in Geostationary Earth Orbits (GEO). At an altitude of approximately 36,000 km above the equator, they have an orbital period equal to the Earth’s rotational period (one day), which allows them to constantly observe the same portion of the Earth’s surface. Seen from ground observers they occupy a fixed position in the sky. The revisit time is therefore effectively zero. Meteosat satellites are able to scan the full earth disc every 15 minutes. The resolution of these images are, however, typically much lower than for SSO satellites due to the very high altitude of the GEO.</p>
    <p>In practice, when ordering the acquisition of new images from an EO satellite, a feasibility assessment is conducted to estimate the turn-around time. Some areas can have a high demand for imagery (important backlog) or persistent cloud cover, which can prolong the effective revisit time.</p>
    &nbsp;
    <h4 id="3.4"><a name="ref_3.4" id="ref_3.4"></a>3.4 Other image quality-related parameters</h4>
    <p>The quality and usefulness of an EO image is governed by several parameters.</p>
    <p><strong style="font-size: 1.25rem;">Bit depth</strong> <br> When an instrument is imaging an area, each pixel is coded on a certain number of bits (typically from 8 to 16 bits) per band. In practice, this relates to the number of nuances that can be recorded: an 8-bit instrument will make the distinction between 2<sup>8</sup>=256 colours whereas a 12-bit instrument will measure the intensity according to a scale of 2<sup>12</sup>=4,096 nuances. Improved bit depth, also called radiometric resolution, aids the ability to discern detail in an image’s brightest and darkest (shadow) areas.</p>
    <p><strong style="font-size: 1.25rem;">Off-nadir angle</strong> <br> In practice, very high-resolution satellite sensors generally do not collect images at nadir, i.e. looking straight down at the target, but acquire images at an angle. Satellite operators report this as the "off-nadir angle" where 0 degrees would be looking straight down. For optical imagery, a typical maximum is an off-nadir angle of 30 degrees.</p>
    <p>A lower off-nadir angle often is desirable, especially in areas of high relief or tall buildings to minimize the so-called "building-lean" effect (see Figure 16). This problem is inherent in remote sensing, as we attempt to accurately represent the three-dimensional surface of the Earth as a two-dimensional image. Objects directly below the centre of the camera lens (i.e. at the nadir) will have only their tops visible, while all other objects will appear to lean away from the centre of the photo such that their tops and sides are visible. If the objects are tall, are far away from the centre of the photo, or if the off-nadir angle is large, the distortion and positional error will be larger.</p>
    &nbsp;
    <div style="width: 370px !important; border: 0; padding: 5px; margin: 0 auto; text-align: center;">
      <img src="images/figure13.png" title="Illustration of the building-lean effect" width="146" height="161" style="display: inline-block; vertical-align: middle; margin-right: 10px;">
      <div style="display: inline-block; vertical-align: middle; font-size: 1.3rem;">
        <strong>Figure 16:</strong> Illustration of the building-lean effect (Source: 
        <a href="https://natural-resources.canada.ca/maps-tools-and-publications/satellite-imagery-elevation-data-and-air-photos/tutorial-fundamentals-remote-sensing/satellites-and-sensors/geometric-distortion-imagery/9401" target="_blank">
          http://www.nrcan.gc.ca/earth-sciences/geomatics/satellite-imagery-air-p...
        </a>)
      </div>
    </div>       
    <p><br><strong style="font-size: 1.25rem;">Sun-elevation angle</strong></p>
    <p>Another parameter to take into account is the angle of the sun above the horizon. Imagery collected with low sun elevation angles may contain data that are too dark to be usable. This will be more pronounced in high-relief areas and areas with taller objects, such as trees and buildings, where low sun elevation angles mean longer shadows will be cast. A typical minimum Sun elevation angle is 30 degrees.</p>
    <p>Due to the fact that most EO satellites are in Sun-Synchronous Orbits, there is little control over the time of day an area of interest is imaged. This is typically set to around 10:30 AM for optical imagery, or 6:00 AM for active imagery (dawn-dusk orbits).</p>
    <p><strong style="font-size: 1.25rem;">Cloud cover</strong> <br> Optical imagery will be perturbed by the presence of clouds above the area of interest. When buying archived imagery, operators provide a reduced-resolution preview graphic ("quicklook") to check if no clouds are concealing the area of interest on the image before purchasing it. When ordering new observation tasking, the customer can ask for a maximum percentage of cloud cover. Customers receive an estimated time window for the acquisition, which maximises the probability of obtaining a cloud-free image. If the observation is unsuccessful, satellite operators can propose another time-window or the acceptance of the acquired images.</p>    
    &nbsp;
    <h4 id="3.5"><a name="ref_3.5" id="ref_3.5"></a>3.5 Accessibility of EO Products</h4>
    <p>The most economical choice of EO Products consists in buying archive images. These have been previously recorded, are present in the database of the EO provider and can be bought as such or be combined to shape the area of interest.</p>
    <p>If no images of the area of interest can be found or if there is no EO product available satisfying the user needs (acquisition date, clouds, resolution…), new observation tasking can be ordered, at a higher cost. The new instructions will be added to the scheduling of the satellite. Depending on the priority of the task and in agreement with the customer, delays can apply (typically 30 to 60 days).</p>
    <p>EO products, especially for high resolution and multi-spectral band images, generally are data heavy files (e.g. around 1 Gb for a 100 km2, colour, 3 bands, 50 cm resolution). These files can be delivered online (ftp downloading, the most common) or via physical media delivery (DVD, HDD or USB key depending on the size of the product).</p>
    <p>Most EO products will be bought through the fully developed commercial market and well established EO product providers. It is, however, possible to get some EO data free of charge through institutional channels (see for example the European Copernicus programme that offers free and open access to <a href="https://sentinel.esa.int/web/sentinel/sentinel-data-access" target="_blank">Sentinel</a> satellites data or the USGS Landsat programme).</p>
    <p>Sensitive areas (military theatres, high-security facilities…) might be subject to restrictions imposed by national governments, especially for high resolution images. EO providers may have to seek governmental approval before acceding to a new tasking order.</p>
    &nbsp;
    <h3 id="4"><a name="ref_4" id="ref_4"></a>4. Some Commonly Used EO Satellite Systems</h3>
    <p>An overview of some of the more commonly used EO satellites in terms of spatial resolution and revisit time is shown in Figure 17.</p>
    <div class="figure large medium-height editable block" id="campbell_1.0-ch04_s01_f01">
      <img src="images/EOsatellites.png" title="Spatial Resolution vs Revisit Time" width="974" height="564">
    
    <p><strong>Figure 17:</strong>&nbsp;Spatial Resolution vs Revisit Time for various example satellites (Source: Satellite Applications Catapult 2017, adapted from EO21 Project).</p>
    </div>
    <p>This has been created for information only. It gathers an arbitrary selection of representative EO satellites and their main parameters. This does not constitute in any way a recommendation for any of the satellites shown.</p>
    &nbsp;
    <h3 id="5"><a name="ref_5" id="ref_5"></a>5. Pricing Policy</h3>
    <p>Providing average prices for Earth Observation products is difficult. The acquisition cost of an image depends on a large number of factors: the image provider, the satellite, the resolution of the image, if it is an archive or a new acquisition, the size of the scene, the demand for this area, the number of images, etc. Moreover, prices catalogues publicly available are most of the time indicative. Real prices might be lower and be negotiated if the image provider is contacted directly.</p>
    <p>Cost and nature of payments can also depend on the proposed business case. For example, a fire-monitoring application using EO data and running for several years might be able to negotiate lower prices and establish a different cost model than pay per image.</p>
    <p>Surcharge may apply for additional processing treatment of images, emergency tasking of a satellite, selection of hard drive as a delivery means, etc. Discounts may apply when tasking over an area of lesser interest (e.g. over the oceans), and when ordering a certain number of images over a long period of time, etc.</p>
    &nbsp;
    <h3><a name="ref_6" id="ref_6"></a>6. How to Access Data</h3>
    <p>Earth Observation data can be acquired through different channels. Free of cost data is generally provided by public agencies, under potential conditions linked to the application envisaged and the nationality of the entity requiring access. Data can also be bought from private companies operating commercial satellites, or by their numerous certified resellers.</p>
    <p>This non-exhaustive list has been created for information only. It gathers an arbitrary selection of representative EO images providers. This does not constitute in any way a recommendation for any of the companies listed.</p>
    <br>
    <p class="m-d-n"></p>
    <strong><span style="color: #000000; font-size: 1.4rem;">Public EO Data Providers</span></strong>
    <br class="m-d-n"><br>
    <table border="0" style="font-size: 1.3rem;">
      <tbody>
          <tr>
              <td>ESA</td>
              <td><a href="https://earth.esa.int/web/guest/home" target="_blank">https://earth.esa.int/web/guest/home</a></td>
          </tr>
          <tr>
              <td>ESA-Sentinel</td>
              <td><a href="https://sentinel.esa.int/web/sentinel/" target="_blank">https://sentinel.esa.int/web/sentinel/</a></td>
          </tr>
          <tr>
              <td>Sentinel Hub</td>
              <td><a href="https://www.sentinel-hub.com/" target="_blank">https://www.sentinel-hub.com/</a></td>
          </tr>
          <tr>
              <td>Eumetsat</td>
              <td><a href="http://www.eumetsat.int/website/home/index.html" target="_blank">http://www.eumetsat.int/website/home/index.html</a></td>
          </tr>
          <tr>
              <td>USGS (Landsat)</td>
              <td><a href="http://earthexplorer.usgs.gov/" target="_blank">http://earthexplorer.usgs.gov/</a></td>
          </tr>
          <tr>
              <td>NOAA</td>
              <td><a href="http://www.ospo.noaa.gov/" target="_blank">http://www.ospo.noaa.gov/</a></td>
          </tr>
          <tr>
              <td>NASA</td>
              <td><a href="https://earthdata.nasa.gov/earth-observation-data" target="_blank">https://earthdata.nasa.gov/earth-observation-data</a></td>
          </tr>
          <tr>
              <td>Japan</td>
              <td><a href="http://www.eorc.jaxa.jp/en/about/distribution/index.html" target="_blank">http://www.eorc.jaxa.jp/en/about/distribution/index.html</a></td>
          </tr>
          <tr>
              <td>China</td>
              <td><a href="http://www.cma.gov.cn/en" target="_blank">http://www.cma.gov.cn/en</a></td>
          </tr>
          <tr>
              <td>India</td>
              <td><a href="http://bhuvan.nrsc.gov.in/bhuvan_links.php" target="_blank">http://bhuvan.nrsc.gov.in/bhuvan_links.php</a></td>
          </tr>
      </tbody>
  </table>
  &nbsp;
  <br><br>
  <strong><span style="color: #000000; font-size: 1.4rem">Commercial EO Data Providers</span></strong>
  <br><br>
  <table border="0" style="font-size: 1.3rem;">
      <tbody>
          <tr>
              <td style="text-align: left;">Digital Globe <br>resellers</td>
              <td style="text-align: left;"><a href="http://www.digitalglobe.com/partners/certified-resellers" target="_blank">http://www.digitalglobe.com/partners/certified-resellers</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">Airbus</td>
              <td style="text-align: left;"><a href="https://www.intelligence-airbusds.com/access-to-our-products/" target="_blank">https://www.intelligence-airbusds.com/access-to-our-products/</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">Deimos</td>
              <td style="text-align: left;"><a href="https://www.deimos-imaging.com/imagery-store/" target="_blank">https://www.deimos-imaging.com/imagery-store/</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">Planet Labs</td>
              <td style="text-align: left;"><a href="https://www.planet.com/" target="_blank">https://www.planet.com</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">Urthecast</td>
              <td style="text-align: left;"><a href="https://www.urthecast.com" target="_blank">https://www.urthecast.com</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">MDA Geospatial <br>Services</td>
              <td style="text-align: left;"><a href="http://gs.mdacorporation.com/Partners/Partners.aspx" target="_blank">http://gs.mdacorporation.com/Partners/Partners.aspx</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">E-geos</td>
              <td style="text-align: left;"><a href="http://www.e-geos.it/index.html" target="_blank">http://www.e-geos.it/index.html</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">Satellite Imaging <br>Corporation</td>
              <td style="text-align: left;"><a href="http://www.satimagingcorp.com/" target="_blank">http://www.satimagingcorp.com/</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">CGG</td>
              <td style="text-align: left;"><a href="http://www.cgg.com/default.aspx?cid=7450" target="_blank">http://www.cgg.com/default.aspx?cid=7450</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">European Space <br>Imaging</td>
              <td style="text-align: left;"><a href="http://www.euspaceimaging.com/" target="_blank">http://www.euspaceimaging.com/</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">Land info</td>
              <td style="text-align: left;"><a href="http://www.landinfo.com/" target="_blank">http://www.landinfo.com/</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">Precision Hawk</td>
              <td style="text-align: left;"><a href="https://www.precisionhawk.com/satellite" target="_blank">https://www.precisionhawk.com/satellite</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">Apollo Mapping</td>
              <td style="text-align: left;"><a href="https://apollomapping.com/" target="_blank">https://apollomapping.com/</a></td>
          </tr>
          <tr>
              <td style="text-align: left;">GHGSat</td>
              <td style="text-align: left;"><a href="https://www.ghgsat.com/%20" target="_blank">https://www.ghgsat.com/</a></td>
          </tr>
      </tbody>
  </table>  
  <p>In the case of the Sentinel EO satellites, developed by ESA for the European Commission’s Copernicus programme, access to data is provided through multiple channels:</p>
  <ol start="1">
    <li>The <a href="https://scihub.copernicus.eu/" target="_blank">Copernicus Open Access Hub</a> provides free and open access to a rolling repository of Sentinel user products. A simple and fast registration is required to create an account, before getting free access to the Sentinel data. The data access is configured to avoid saturation resulting from massive downloads by a limited number of users (e.g. maximum number of parallel downloads, maximum volume per retrieval).</li><br>
    <li>A collaborative ground segment is also in development in several member states (e.g. <a href="http://sentinels.space.noa.gr/" target="_blank">http://sentinels.space.noa.gr/</a> (Greece) or <a href="http://sedas.satapps.org/" target="_blank">http://sedas.satapps.org/</a> (UK)). It is intended to allow complementary access to Sentinel data and/or to specific data products by establishing additional pick-up points (e.g. mirror sites). It is composed of elements funded by third parties (i.e. from outside the ESA/EU Copernicus programme).</li><br>
    <li><a href="https://spacedata.copernicus.eu/" target="_blank">Copernicus Space Component Data Access</a> (CSCDA) is restricted to users eligible to Copernicus Services, as defined by the European Commission (e.g. institutions and bodies of the EU, participants to a research project financed under the EU research programmes, international organisations and NGOs...). Access is provided with committed performances, together with possibilities to order specific tasking of the satellites participating in Copernicus.</li>
  </ol>
  &nbsp;
  <h3 id="7"><a name="ref_7" id="ref_7"></a>7. Future Trends</h3>
  <p>In recent years some new trends have started to develop in the field of Earth Observation.</p>
  <p>The sector is moving from using a few large, complicated and costly EO satellites to establishing constellations of numerous small and cheap satellites. The focus is changing from increasing spatial resolution to the search for better coverage and revisit time, with the aim of providing near-real time Earth Observation monitoring for all. Ever increasing amounts of data are being produced and Earth Observation, which once was restricted to a limited subset of highly trained users, is becoming more accessible and ubiquitous. Following the entrance of new actors, prices are anticipated to decrease in the coming years. The business model of EO providers is also expected to evolve from the selling of data (e.g. EO images of shopping mall car parks) to the selling of intelligent information (e.g. daily report on the affluence to the shopping mall, measured by counting the number of cars in the car parks).</p>
  <p>Opportunities will further arise with the advent of new technologies such as new types of sensor, video from space, reconfigurable payload technologies offering greater in-orbit flexibility, etc</p>
  &nbsp;
  <h3 id="8"><a name="ref_8" id="ref_8"></a>8. Reference Sources</h3>
  <p>The realisation of this guide has been done using many sources of information publicly available on the internet and listed hereunder, additionally to the ones cited in the text:</p>
  <p><a href="http://www.esa.int/Our_Activities/Observing_the_Earth" target="_blank">http://www.esa.int/Our_Activities/Observing_the_Earth</a></p>
  <p><a href="http://www.esa.int/Our_Activities/Observing_the_Earth/Copernicus/Altimetry_missions" target="_blank">http://www.esa.int/Our_Activities/Observing_the_Earth/Copernicus/Altimetry_missions</a></p>
  <p><a href="https://sentinel.esa.int/web/sentinel/user-guides" target="_blank">https://sentinel.esa.int/web/sentinel/user-guides</a></p>
  <p><a href="http://www.dlr.de/eoc/en/desktopdefault.aspx/tabid-5354/10125_read-21375/" target="_blank">http://www.dlr.de/eoc/en/desktopdefault.aspx/tabid-5354/10125_read-21375/</a></p>
  <p><a href="https://www.nasa.gov/directorates/heo/scan/communications/outreach/funfacts/index.html" target="_blank">https://www.nasa.gov/directorates/heo/scan/communications/outreach/funfacts/index.html</a></p>
  <p><a href="http://www.atmos.washington.edu/weather/aboutir.shtml" target="_blank">http://www.atmos.washington.edu/weather/aboutir.shtml</a></p>
  <p><a href="http://www.nrcan.gc.ca/earth-sciences/geomatics/" target="_blank">http://www.nrcan.gc.ca/earth-sciences/geomatics/</a></p>
  <p><a href="http://www.intelligence-airbusds.com/" target="_blank">http://www.intelligence-airbusds.com/</a></p>
  <p><a href="http://www.satimagingcorp.com/" target="_blank">http://www.satimagingcorp.com/</a></p>
  <p><a href="https://www.digitalglobe.com/" target="_blank">https://www.digitalglobe.com/</a></p>
  <p><a href="http://www.landinfo.com/" target="_blank">http://www.landinfo.com/</a></p>
  <p><a href="http://www.landinfo.com/EIJ.Optical-Article.pdf" target="_blank">http://www.landinfo.com/EIJ.Optical-Article.pdf</a></p>
  &nbsp;
  <h3 id="8"><a name="ref_9" id="ref_9"></a>9. Useful Links</h3>
  <p>Additional reading material is listed below:</p>
  <p>CEOS database of all Earth Observation instruments sent into space (scientific payloads as well):&nbsp;<br><a href="http://database.eohandbook.com/database/missiontable.aspx" target="_blank">http://database.eohandbook.com/database/missiontable.aspx</a></p>
  <p>Smartphone app that notifies when an imaging satellite is passing over a specified location, providing on-demand access to the latest commercial satellite imagery, and allowing users to task a high resolution satellite to take a new picture:&nbsp;<br><a href="https://www.spymesat.com/" target="_blank">https://www.spymesat.com/</a></p>
  <p>Tutorial about the fundamentals of Remote Sensing, created by the Government of Canada: <br><a href="http://www.nrcan.gc.ca/earth-sciences/geomatics/satellite-imagery-air-photos/satellite-imagery-products/educational-resources/9309" target="_blank">http://www.nrcan.gc.ca/earth-sciences/geomatics/satellite-imagery-air-photos/satellite-imagery-products/educational-resources/9309</a></p>  
  &nbsp;
    <h3><a name="eo_acro" id="eo_acro"></a>10. Acronyms</h3>
    <ul><li><strong>CSCDA:</strong> Copernicus Space Component Data Access</li>
    <li><strong>DEM:</strong> Digital Elevation Model</li>
    <li><strong>DSM:</strong> Digital Surface Model</li>
    <li><strong>DTM:</strong> Digital Terrain Model</li>
    <li><strong>EO:</strong> Earth Observation</li>
    <li><strong>GEO:</strong> Geostationary Orbit</li>
    <li><strong>GSD:</strong> Ground Sampling Distance</li>
    <li><strong>IR:</strong> Infrared</li>
    <li><strong>LWIR:</strong> Long-Wavelength Infrared</li>
    <li><strong>MWIR:</strong> Mid-Wavelength Infrared</li>
    <li><strong>NIIRS:</strong> National Imagery Interpretability Rating Scale</li>
    <li><strong>NWP:</strong> Numerical Weather Prediction</li>
    <li><strong>RPAS:</strong> Remotely Piloted Aircraft Systems</li>
    <li><strong>SAR:</strong> Synthetic Aperture Radar</li>
    <li><strong>SSO:</strong> Sun-Synchronous Orbit</li>
    <li><strong>SWIR:</strong> Short-Wavelength Infrared</li>
    <li><strong>UV:</strong> Ultraviolet</li>
    <li><strong>VHR:</strong> Very High Resolution</li>
    <li><strong>VNIR:</strong> Visible and Near Infrared</li>
    </ul>
    <br><br>
    </div>
    </section>
    <footer class="u-align-center u-clearfix u-footer u-white u-footer" id="sec-9996">
      <div class="u-clearfix u-sheet u-valign-middle u-sheet-1">
        <p class="u-small-text u-text u-text-variant u-text-1">
        Made with 💙&nbsp;by
          <a href="https://www.linkedin.com/in/nehorayshimoni/" class="u-active-none u-border-none u-btn u-button-link u-button-style u-hover-none u-none u-text-palette-1-base u-btn-1" target="_blank">Nehoray Shimoni</a>&nbsp;
        </p>
      </div>
      <div class="go-top-wrapper" style="display: block;">
      <a class="go-top fa-stack fa-2x" href="#top">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-angle-up fa-stack-1x fa-inverse"></i>
      </a>
    </div>
    </footer>
  </body>
 </html>